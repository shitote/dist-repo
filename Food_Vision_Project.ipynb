{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/YbZ4H1nGdBcYcw+j6fLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shitote/dist-repo/blob/main/Food_Vision_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Food Vision Project"
      ],
      "metadata": {
        "id": "7RnBCUkzoywC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mixed Precision training.\n",
        "This needs access to a gpu with capabilities more than 7.0"
      ],
      "metadata": {
        "id": "dXF-pXFApONF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "s_1KSHsIp5MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n"
      ],
      "metadata": {
        "id": "fS8w9ybEp9OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys\n"
      ],
      "metadata": {
        "id": "cC_TR4_erVs6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use tf dataset (TFDS) to download data."
      ],
      "metadata": {
        "id": "4RdhKH5Yrxg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "MCtLpAa8sCKZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all available datasets in tfds\n",
        "datasets_list = tfds.list_builders()\n",
        "print(\"food101\" in datasets_list)"
      ],
      "metadata": {
        "id": "niOkS62-tSDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
        "                                             split=[\"train\", \"validation\"],\n",
        "                                             shuffle_files=True,\n",
        "                                             as_supervised=True,  # Returns the data in tuple format\n",
        "                                             with_info=True)"
      ],
      "metadata": {
        "id": "wt6bIE4ztoI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_info.features"
      ],
      "metadata": {
        "id": "APQp1UDmzDBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names.\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "class_names[:10]"
      ],
      "metadata": {
        "id": "GM1yxl7T-G2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration\n",
        "\n",
        "to become one with the data, you have to find:\n",
        "* clas names.\n",
        "* image shape.\n",
        "* the data type of the input data.\n",
        "* whta the labels look like.\n",
        "* do the labels match with the classnames.\n"
      ],
      "metadata": {
        "id": "u86s0Lmd-mAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take one sample of the treining data.\n",
        "train_one_sample = train_data.take(1)\n",
        "train_one_sample"
      ],
      "metadata": {
        "id": "UhHsFJWW-53P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_one_sample:\n",
        "  print(f\"\"\"\n",
        "    Image shape: {image.shape}\n",
        "    image data: {image.dtype}\n",
        "    Target class (tensor form): {label}\n",
        "    class name (str form): {class_names[label.numpy()]}\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "uqIsnloi_5m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot an image from Tensorflow datasets"
      ],
      "metadata": {
        "id": "YrFwKCdhBPgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label.numpy()])\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "GhY0Q3J_CUwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "import tensorflow as tf\n",
        "def preprocess_img(image, label, img_shape=224):\n",
        "  \"\"\"\n",
        "  Converts image datatype from uint8 to float32 and reshape image to [\n",
        "    image_shape image_shape, color_channels\n",
        "  ]\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(image, [img_shape, img_shape])\n",
        "  return tf.cast(image, tf.float32), label"
      ],
      "metadata": {
        "id": "CicdOtTeDD_T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess a single sample image and check the output\n",
        "preprocessed_img = preprocess_img(image, label)[0]\n",
        "print(f\"Image before:\\n {image[:2]}..., \\nShape: {image.shape}, \\nDatatype:{image.dtype} \")\n",
        "print(f\"image after:\\n {preprocessed_img[:2]}..., \\nShape:{preprocessed_img.shape}, \\nDatatype: {preprocessed_img.dtype}\")"
      ],
      "metadata": {
        "id": "YG9-VcX7C7YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch and prepare datasets\n",
        "\n",
        "Make data input pipeline to make the model run really faster."
      ],
      "metadata": {
        "id": "ur4cfScGC8LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map preprocessing function to training (and parallelize)\n",
        "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE )\n",
        "# shuffle training data and trun it into batches\n",
        "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Map the preprocessing function to the test data.\n",
        "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "-jhpFx6zTdqN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "h95GXNzhXHMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create modelling callbacks"
      ],
      "metadata": {
        "id": "AfP4VzTDXLXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "checkpoint_path = \"model_checkpoints/cp.ckpt\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      monitior='val_acc',\n",
        "                                                      save_best_only=True,\n",
        "                                                      save_weights_only=True,\n",
        "                                                      verbose=0)"
      ],
      "metadata": {
        "id": "fUxjRWRWaxHq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up mixed Precission training"
      ],
      "metadata": {
        "id": "_tkt6Ks0cCln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn on mixed precission training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")  # sets the global data to precision\n"
      ],
      "metadata": {
        "id": "LVfTnuehcI6E"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "id": "mBTBTIDPdfJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction model"
      ],
      "metadata": {
        "id": "0b1OL69RfBOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Create base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create functional model.\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(len(class_names))(x)\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name='softmax_flaot32')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "qsLvdY-IivQZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5iz1FzR8k8iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking layer dtype policy\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)\n"
      ],
      "metadata": {
        "id": "ECE-0wfNlu7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dtype attributes in the base model.\n",
        "for layer in model.layers[1].layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "id": "Z9GJlBkCnrrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "id": "s2KLPx_5o1_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.set_global_policy(\"float32\")"
      ],
      "metadata": {
        "id": "O4B4F26VpgMp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the feature extraction model"
      ],
      "metadata": {
        "id": "FTA4PoDSpoS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_101_food_classes_feature_extraction = model.fit(train_data,\n",
        "                                                        epochs=3,\n",
        "                                                        steps_per_epoch=(len(train_data)),\n",
        "                                                        validation_data=test_data,\n",
        "                                                        validation_steps=int(0.15 * len(test_data)),\n",
        "                                                        callbacks=[create_tensorboard_callback('training_log',\n",
        "                                                                                               \"efficientnet_all_data\"),\n",
        "                                                                   model_checkpoint])"
      ],
      "metadata": {
        "id": "Z15bqF4kp8_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIgp4ZA5rb7I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}