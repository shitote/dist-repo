{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shitote/dist-repo/blob/main/introduction_to_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86MHHnkiZ5_N"
      },
      "source": [
        "## NLP are also refered to as a sequence to sequence problems.(seq2seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXqoDDLFagyl"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob9rtJpeankg"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# import helper functions.\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJl1geoVcKlX"
      },
      "source": [
        "## Get a text dataset\n",
        "Kaggle's introduction to NLP dataset (text samples of Tweets labbelled as disaster or not disarster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5W5evpQeXLy"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip the data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqsfqFtpkrh6"
      },
      "source": [
        "## Visualizing a text dataset.\n",
        "\n",
        "Read the text file in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYQT75MTlo5O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKiq1duImuUy"
      },
      "outputs": [],
      "source": [
        "train_df[\"text\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUIwWNutnGYD"
      },
      "outputs": [],
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnlM03c1ndxL"
      },
      "outputs": [],
      "source": [
        "# Note that the test data frame have no target values.\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0v1hsf-loJV"
      },
      "outputs": [],
      "source": [
        "# Find Out if the dataset is baklanced or not?\n",
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTtripk9mFRA"
      },
      "outputs": [],
      "source": [
        "# Find the number of total samples.\n",
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sq6kjGAq2oj"
      },
      "outputs": [],
      "source": [
        "# visualize random training examples.\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5)\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+10].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(Not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzN4JjV0tB8D"
      },
      "source": [
        "### Split the data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bDcdrqGPvMyq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uY_TYHhvY2d"
      },
      "outputs": [],
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAMBUEubwxnK"
      },
      "outputs": [],
      "source": [
        "train_sentences[:10], train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McnOnqvsxeFX"
      },
      "source": [
        "## Coverting text to numbers\n",
        "* Tokenization - This is direct mapping of token to number\n",
        "* Emmbedding - Create a matrix of feature vectors for each token (\n",
        "    the size fo the feature vector can be defined for each token embedding can be learned\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7P6AEDb9wPU"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hzDyXM1Q94_k"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters.\n",
        "text_vectorizer = TextVectorization(max_tokens=None,  # How many words in the vocabulary (automaticaly add <oov>)\n",
        "                                    standardize='lower_and_strip_punctuation',  # Remove the fluf\n",
        "                                    split='whitespace',\n",
        "                                    ngrams=None,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=None,\n",
        "                                    pad_to_max_tokens=False\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo47qOG1BOLP"
      },
      "outputs": [],
      "source": [
        "len(train_sentences[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3DXOjVICCyx"
      },
      "outputs": [],
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NqGcafpODGeA"
      },
      "outputs": [],
      "source": [
        "# set text vectorization variables\n",
        "max_vocab_length = 1000\n",
        "max_length = 16\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nhTl6yreEoxb"
      },
      "outputs": [],
      "source": [
        "# Fit the text vectorizer to the trainin text\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bbs-MnNFTgS"
      },
      "outputs": [],
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There are floods everywhere\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF6fAXHWFore"
      },
      "outputs": [],
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text: \\n {random_sentence}\\n\\n Vectorized version:')\n",
        "text_vectorizer([random_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuvXn84yG241"
      },
      "outputs": [],
      "source": [
        "# et the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5]\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "print(f'Number of words i vocab: {len(words_in_vocab)}')\n",
        "print(f'5 most common words: {top_5_words}')\n",
        "print(f'5 least common words: {bottom_5_words}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F4n-S76HivG",
        "outputId": "06bef2b3-cb5a-49b3-fdba-c42d86a627ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x7a02dca488b0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "### Create an Embedding using an embedding layer\n",
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,  # set the input shape\n",
        "                            output_dim=128,  # output shape\n",
        "                            input_length=max_length # how long is each input\n",
        "                            )\n",
        "\n",
        "embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHyIeXNfgaO2"
      },
      "outputs": [],
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: \\n {random_sentence} \\\n",
        "      \\n\\nEmbedding version: \")\n",
        "\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTVcMZNNh_6r"
      },
      "source": [
        "## Modelling a text dataset (running a serries of experiments)\n",
        "\n",
        "The data is now in numbers it is time to build a series of modelling experiments.\n",
        "\n",
        "* model 0: naive bayes (baseline), this is from sklearn ML\n",
        "* model 1: Feed-forward neural network (dence model)\n",
        "* model 2: LSTM model (RNN)\n",
        "* model 3: GRU model (RNN)\n",
        "* model 4: Bidirectional Neural Networks(RNN)\n",
        "* model 5: !D Convolutional neural nerworks (CNN)\n",
        "* model 6: Tensoflow hub Pretrained Feature extraction (using transfer learnin NLP)\n",
        "* model 7: Same as model 6 with 10% of training data.\n",
        "\n",
        "THs use od standard steps of modelling in tensorflow:\n",
        "* Crreate a model.\n",
        "* Build a model.\n",
        "* FIt the model.\n",
        "* Evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPtJWokW6IgG"
      },
      "source": [
        "### Model 0: Getting a baseline.\n",
        "\n",
        "**NOte** It is a better proctice to use non-DL alorithms to create the baseline model since they are fast and easy to train then latter impliment it with the DL to improve the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hcSjw8Z60Fu"
      },
      "outputs": [],
      "source": [
        "# Trun the data into numerical.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a tokenization and modellin pipeline.\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),   #Convert words to numbers.\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B5WnTsn8Y2i"
      },
      "outputs": [],
      "source": [
        "# Baseline model evaluation.\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Baseline model score: {baseline_score*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfNK5RbC8-69"
      },
      "outputs": [],
      "source": [
        "# Make predictions.\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7u5lDxk9nA8"
      },
      "outputs": [],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "anqwvlic9wvU"
      },
      "outputs": [],
      "source": [
        "# Fuction to evalate: accuracy, precision, recall, f1_score.\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "  \"\"\"\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkXvM8j1--aO"
      },
      "outputs": [],
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1PtJn-7Ebqh"
      },
      "source": [
        "### Model_1: A simple dence model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uLB_f0ygTFhx"
      },
      "outputs": [],
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "SAVE_DIR = 'model_logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TYvA_BJPTpro"
      },
      "outputs": [],
      "source": [
        "# Build a model using the functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)  # Input are 1-dimensional array of string.\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzK6fvzrivNb"
      },
      "outputs": [],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tF2fgHvFYW6P"
      },
      "outputs": [],
      "source": [
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPH3AnB5Y2Xl"
      },
      "outputs": [],
      "source": [
        "train_sentences.shape, train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6smXLnqojg7z"
      },
      "outputs": [],
      "source": [
        "train_labels = tf.reshape(train_labels, (-1, 1))\n",
        "val_labels = tf.reshape(val_labels, (-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMbB0T2dW2S4"
      },
      "outputs": [],
      "source": [
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name='model_1_dence')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBzNZnSgXHNA"
      },
      "outputs": [],
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIVSSEkElMlb"
      },
      "outputs": [],
      "source": [
        "# Make somce Predictions and evaluate them\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZJCySk0lq0L"
      },
      "outputs": [],
      "source": [
        "model_1_pred_probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h__oAGail3Sk"
      },
      "outputs": [],
      "source": [
        "# Convert the models prediction into probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u0TZlIFohbH"
      },
      "outputs": [],
      "source": [
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpkZA1PQpaYI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UJoynq4pMWm"
      },
      "source": [
        "## Visualize the learned embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8afSm5lkFu6N"
      },
      "outputs": [],
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eoa6DPxtFyGi"
      },
      "outputs": [],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLLYLRZ2MKzG"
      },
      "outputs": [],
      "source": [
        "# Get the wight metrix of embeddin layer\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D96voT7rMz-z"
      },
      "source": [
        "### Create embedding files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qpc5y5qkOHAy"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + '\\n')\n",
        "  out_m.write(word + '\\n')\n",
        "out_v.close()\n",
        "out_m.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eONy_EslPjNP"
      },
      "outputs": [],
      "source": [
        "# Dowload file from colab to upload to the projector\n",
        "# word to vector jay alama\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download(\"vectors.tsv\")\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqjCEXoxTE8e"
      },
      "source": [
        "## Recurrent Neural Networks (RNN)\n",
        "\n",
        "RNN are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neuaral network is to use the representatoin of a previous input to aid the representation of a later input\n",
        "\n",
        "The internals of RNN:\n",
        "- MIT's sequence modelling.\n",
        "- Chris olah's intor to LSTMs:\n",
        "- Andrej Kapathy's the unreasonable effectiveness of recurrent neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIwQr6j7FFIa"
      },
      "source": [
        "### Model 2: LSTM\n",
        "LSTM = Long short term memory (One of the most popular LSTM cells)\n",
        "* The structure of an RNN trypically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "6L7Bu3P8Gz9M"
      },
      "outputs": [],
      "source": [
        "# Tenh\n",
        "# Create an LSTM model.\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='model_2_LSTM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "nJge818hIs28"
      },
      "outputs": [],
      "source": [
        "# Compile the model.\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFxjyZVtKv8a"
      },
      "outputs": [],
      "source": [
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, 'model_2_LSTM')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXbCMDORLR8K"
      },
      "outputs": [],
      "source": [
        "# Make predictions with the LSTM model.\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvrFxS8KLsrF"
      },
      "outputs": [],
      "source": [
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm2BvasCMKm7"
      },
      "outputs": [],
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true = val_labels,\n",
        "                                    y_pred = model_2_preds)\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFRE0R8yMuZS"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "This is also a popular RNN component GRU - gated recurrent Unit\n",
        "\n",
        "The GRU have the same features to an LSTM cell but have less parameters,\n",
        "\n",
        "RFewources:\n",
        "understantin the GRU networks by simion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZJwrefbuN_4z"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64, return_sequences=True)(x)\n",
        "# x = layers.LSTM(64)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name='model_3_GRU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "box_LNEPOVq2"
      },
      "outputs": [],
      "source": [
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "oHh_19UGRWxU"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28gJ2G-CSjTw"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_3_GRU')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxYBU6x5TL2P"
      },
      "outputs": [],
      "source": [
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvOpKIrxTijo"
      },
      "outputs": [],
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QE9SDO3UOPq"
      },
      "outputs": [],
      "source": [
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwqOXfMEUkyz"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (the same way you will read a kiswahili sentence).\n",
        "The bidirection RNN go from right to let as well as from  left to right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "BctOpVnNcX92"
      },
      "outputs": [],
      "source": [
        "# Build a bidirection RNN\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name='model_4_bidirectional')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCJVP8t4eNnW"
      },
      "outputs": [],
      "source": [
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "JmpBuLlxfPCy"
      },
      "outputs": [],
      "source": [
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer= tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVpsqIuQgMI1"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_4_bidirectional')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkdbUYJvhDTy"
      },
      "outputs": [],
      "source": [
        "# make predictions.\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLrhP5lLilJY"
      },
      "outputs": [],
      "source": [
        "# Turn the results into a comparable features.\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA0TIkMyjBm2"
      },
      "outputs": [],
      "source": [
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yvpx5ppjQIr"
      },
      "source": [
        "## Convolutional Neural Networks for text and othet types od seu=quences\n",
        "\n",
        "The typical structure of a convolutional neural network\n",
        "\n",
        "Input (text) -> Tokenization -> Embedding -> Layers (typically conv1D + pooling) -> Outputs (class probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHyzrPkLl1V_"
      },
      "source": [
        "### Model 5: conv1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QdbnVTCmJAW"
      },
      "outputs": [],
      "source": [
        "# Make a test of the embedding layer, conv1D layer and max pooling layers\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,\n",
        "                        activation='relu',\n",
        "                        padding='valid')\n",
        "conv_1d_output = conv_1d(embedding_test)  # pass the test embeddin into the conv1d layer.\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)   # get the most important fearutes.\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unnFlw0vpDCz"
      },
      "outputs": [],
      "source": [
        "embedding_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af3b9Pv1rCh1"
      },
      "outputs": [],
      "source": [
        "conv_1d_output[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf5qYuXerKye"
      },
      "outputs": [],
      "source": [
        "max_pool_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm4Z0dAhrfO1"
      },
      "outputs": [],
      "source": [
        "# Create d dimensional convolutional neural network layer to model sequences.\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, strides=1, activation='relu', padding= 'valid')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name='model_5_conv1D')\n",
        "\n",
        "# Compile the model and fit it ata one go\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "EXfL_IKjvDEJ"
      },
      "outputs": [],
      "source": [
        "train_sentences_tensor = tf.convert_to_tensor(train_sentences)\n",
        "val_sentences_tensor = tf.convert_to_tensor(val_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZMBpIDSpYX-"
      },
      "outputs": [],
      "source": [
        "# fit model 5\n",
        "model_5_history = model_5.fit(train_sentences_tensor,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences_tensor, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'conv1D')])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:5]"
      ],
      "metadata": {
        "id": "PZyJ7e0p8uP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the results comparerable.\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "id": "V928qrCF9Bxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTH-ypWAr1sk"
      },
      "source": [
        " ## # Model 6: Tensorflow Hub Pretrained Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Iscs2usv3JdC"
      },
      "outputs": [],
      "source": [
        "# import tensorflow_hub as hub\n",
        "# import tensorflow as tf\n",
        "\n",
        "# english_sentences = tf.constant([\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"])\n",
        "\n",
        "# preprocessor = hub.KerasLayer(\n",
        "#     \"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\")\n",
        "# encoder = hub.KerasLayer(\n",
        "#     \"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/cmlm-en-base/1\")\n",
        "\n",
        "# english_embeds = encoder(preprocessor(english_sentences))[\"default\"]\n",
        "\n",
        "# print (english_embeds)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-text"
      ],
      "metadata": {
        "id": "_tn25GF22pu_"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "00V6zZUeLjH9"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "mTWJprMZ2zeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from json import encoder\n",
        "## Model 6: Tensorflow hub pretrained sentence encoder\n",
        "Transfer learning for NLP, Specificaly use tensorflow hub universal sentence encoder"
      ],
      "metadata": {
        "id": "KsjekOFUSpDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "h87MN6S6QrsG"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "embed = model\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you add the universal sentences encoder to a sentence, it converts it to numbers\"])\n",
        "print(embed_samples[0][:50])\n"
      ],
      "metadata": {
        "id": "0SlM5x85MIzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples"
      ],
      "metadata": {
        "id": "X-Bky4jVjdHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "TMO8yVW19rQo"
      },
      "outputs": [],
      "source": [
        "# Create a keras layer using pretrained layer from Hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "    input_shape=[],\n",
        "    dtype=tf.string,\n",
        "    trainable=False,\n",
        "    name=\"USE\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model using sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "], name='model_6_USE')"
      ],
      "metadata": {
        "id": "6nmTyA5p2MZo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "model_6.summary()"
      ],
      "metadata": {
        "id": "SaPQxWSbl84e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRain a classifier on top of USE embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'tf_hub_sentence_encoder')])"
      ],
      "metadata": {
        "id": "44WIxGSmWRhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions with USE TF HUb model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "id": "d05MdoKQXfC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "id": "aiq6QufIX-2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the model 6 performance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "id": "cxVU5iuaYZag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# improve the preformance of the  model\n",
        "model_7 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "], name='model_7_USE')"
      ],
      "metadata": {
        "id": "BT2-6_BRY_fo"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model.\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_7.summary()"
      ],
      "metadata": {
        "id": "oGA3-zZ2aBLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model.\n",
        "model_7_history = model_7.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_7_USE')])"
      ],
      "metadata": {
        "id": "UmbWa0XqaWcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions for the model.\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:5]"
      ],
      "metadata": {
        "id": "MQ-Ph9_WbglE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make the prediction result comparerable.\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:5]"
      ],
      "metadata": {
        "id": "TLMR1WW5cLFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate model 7 presormance metrics.\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "id": "LIMZpHX5cgXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: TF HUB Pretrained USE with only 10% of the training data"
      ],
      "metadata": {
        "id": "AlEgU9XjdLEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create subsets of 10% of training data\n",
        "train_10_percent = train_df_shuffled[['text', 'target']].sample(frac=0.1, random_state=42)\n",
        "train_10_percent.head(), len(train_10_percent), len(train_df_shuffled)"
      ],
      "metadata": {
        "id": "U2hRdPYbegV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an element of data leakages.\n",
        "train_sentences_10_percent = train_10_percent['text'].to_list()\n",
        "train_labels_10_percent = train_10_percent['target'].to_list()\n",
        "len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnClcKapetlV",
        "outputId": "71378413-5022-4aa3-9afb-0b6dad9d6aad"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(761, 761)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Solve the proble of data leakage.\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSpFCdt1y-5A",
        "outputId": "15f5c24a-d8ac-44f5-a9bd-12d50194e474"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(685, 685)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_10_percent[:10]"
      ],
      "metadata": {
        "id": "LdvNO0Wbzx_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(np.array(train_labels_10_percent).ravel()).value_counts()"
      ],
      "metadata": {
        "id": "A6qOmsmR0tTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhwUBJ2kgcaY"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_10_percent[:5]"
      ],
      "metadata": {
        "id": "UtmUeUgMhE-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone model 6 to adapt it to model 7."
      ],
      "metadata": {
        "id": "L_sqUWTxhlN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# compile the model.\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "model_7.summary()"
      ],
      "metadata": {
        "id": "EDuzuL7fnWIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                    'tf_hub_sentence_encoder_10_percent_correct')])"
      ],
      "metadata": {
        "id": "8K-NPoRroAVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction of the models that is trained on 10 percent of the data.\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:5]"
      ],
      "metadata": {
        "id": "o686awYTrh8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "id": "82Y8KMvlsF_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 7 predictions evaluations.\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "id": "s4kBH4Oish25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare the performance of all the models"
      ],
      "metadata": {
        "id": "GSJ9xHzjs78Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combine model results into a dataframe\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_USE\": model_6_results,\n",
        "                                  \"7_tf_hub_USE_10%\": model_7_results\n",
        "                                  })\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "B_U-mB1y66eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results['accuracy'] = all_model_results['accuracy']/100\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "baKBs_HL7Si6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe all_model_results: scatter\n",
        "\n",
        "import altair as alt\n",
        "alt.Chart(all_model_results).mark_circle().encode(\n",
        "    x='accuracy',\n",
        "    y='precision',\n",
        "    color=alt.Color('f1', scale=alt.Scale(scheme='viridis'))\n",
        ").interactive()\n"
      ],
      "metadata": {
        "id": "H6wHeZ_1_HX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploa and compare all of the model results\n",
        "all_model_results.plot(kind='bar', figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0))"
      ],
      "metadata": {
        "id": "6eVjxln0-4ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1_score.\n",
        "all_model_results.sort_values(\"f1\", ascending=False)['f1'].plot(kind='bar', figsize=(10, 7))"
      ],
      "metadata": {
        "id": "0M4IdKMTAF_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resource:** checkout weihts and bieses for experiment tracking"
      ],
      "metadata": {
        "id": "e_oNwGZbBgv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and load the model\n",
        "\n",
        "There are two main formats to save the model to in TensorFlow:\n",
        "1. The HDF4 format,\n",
        "2. The `SavedModel` format"
      ],
      "metadata": {
        "id": "CMntCJvzC07y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "id": "HW0jZ-OSDdAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save TF hub SE model to HDF5\n",
        "model_6.save('model_6.h5')"
      ],
      "metadata": {
        "id": "Zq2kh_g_Gew7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with custom hub layer (reauored by HDF5)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model('model_6.h5',\n",
        "                                            custom_objects={'KerasLayer': hub.KerasLayer})"
      ],
      "metadata": {
        "id": "5IiQFKrsGtn3"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluat the loaded model.\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "gviiS-CCHpZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the saved model format\n",
        "model_6.save(\"model_6_savedModel_format\")"
      ],
      "metadata": {
        "id": "A_pdTOPGH9EC"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model_6_savedModel = tf.keras.models.load_model('model_6_savedModel_format')"
      ],
      "metadata": {
        "id": "xoxNhbeZIXnr"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the evaliations of the save model.\n",
        "load_model_6_savedModel.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "9Bif-H2dI8FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the most wrong examples\n",
        "\n",
        "* If the model still isn't perfect, what examples is it getting wrong?\n",
        "* And of those wrong examples which one is it getting *most* wron (Those with the prediction probabilities closser to the opposite class)\n",
        "\n",
        "**This is call data driven data exploration or active learning**"
      ],
      "metadata": {
        "id": "P_86J2bKJXYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "metadata": {
        "id": "1sFDEYgeLZNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained = tf.keras.models.load_model('08_model_6_USE_feature_extractor')\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "F0FH05ZcM0X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions with the loaded model\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10]"
      ],
      "metadata": {
        "id": "6cnBck1pNrG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained_pred_probs = tf.squeeze(model_6_pretrained_pred_probs)\n",
        "model_6_pretrained_pred_probs.shape"
      ],
      "metadata": {
        "id": "hsOI-yFdSbqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3H65nbl_Ts2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataFrame\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": tf.squeeze(tf.round(val_labels)),\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": model_6_pretrained_pred_probs})\n",
        "val_df.head()"
      ],
      "metadata": {
        "id": "AAE2z4SNPArL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the wrong prodictions and sort by prediction probabilities.\n",
        "most_wrong = val_df[val_df['target'] != val_df['pred']].sort_values('pred_prob', ascending=False)\n",
        "most_wrong[:10]"
      ],
      "metadata": {
        "id": "C8QOkTXeQYvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred} Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-------------------\\n\")"
      ],
      "metadata": {
        "id": "7dakmzOzWisr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false neatives\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text: \\n {text}\")\n",
        "  print(\"-------------\\n\")"
      ],
      "metadata": {
        "id": "YzIJK_CN2EpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "u49gku7q3fei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Makin prediction on the test dataset."
      ],
      "metadata": {
        "id": "yMnRysGb4nqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " test_sentences = test_df['text'].to_list()\n",
        " test_sentences[:6]"
      ],
      "metadata": {
        "id": "45uXKbUm5Lm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test dataset and visualizing them.\n",
        "test_sentences = test_df['text'].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample]))  # the model expets a list.\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text: \\n {test_sample}\")\n",
        "  print(\"---------\\n\")"
      ],
      "metadata": {
        "id": "eRrhGcFp6C7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The speed/score tradeoff"
      ],
      "metadata": {
        "id": "XOcHIMSz7IWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make proedictions on samples.\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter()  # ge start time\n",
        "  model.predict(samples)  # make predictions\n",
        "  end_time = time.perf_counter()  # et finish time\n",
        "  total_time = end_time - start_time\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return  total_time, time_per_pred"
      ],
      "metadata": {
        "id": "Y63u9fjX9cOu"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(\n",
        "    model=model_6_pretrained,\n",
        "    samples=val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QmtxYOk_FmV",
        "outputId": "c2677bfb-a780-49f2-827f-6469f729bf51"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.27332212800047273, 0.0003586904566935338)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(\n",
        "    model=model_0,\n",
        "    samples=val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "id": "B5HonwJ-__-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
        "                                               y_pred=model_6_pretrained_preds)\n",
        "model_6_pretrained_results"
      ],
      "metadata": {
        "id": "2LNVWzRgApaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(11, 9))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label='baseline')\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results['f1'], label='tf_hub_sentence_encoder')\n",
        "plt.legend()\n",
        "plt.title(\"F1 score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-score\")"
      ],
      "metadata": {
        "id": "Bet9WBoOBbP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dunuvHYGC0qf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMddUR72ILyBitOAPGYUoQ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}